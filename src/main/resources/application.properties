spring.application.name=spring-ai-101

logging.level.com.broadcom.tanzu.demos=DEBUG
logging.level.io.micrometer.registry.otlp=OFF
logging.level.io.opentelemetry.exporter.internal.http=OFF

# Pick the AI provider used by the app: openai, mistralai, azure, ollama.
app.ai-provider=openai

# Set max requests per second when using Mistral AI.
app.mistralai.rps=5

# Observation configuration.
# Use Jaeger UI to track network calls: http://localhost:16686
management.observations.key-values.application=${spring.application.name}
management.observations.key-values.service=${spring.application.name}
management.observations.key-values.source=${spring.application.name}-${random.uuid}
management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://localhost:4318/v1/traces

# Disable Spring AI auto configuration for ChatClient, as this app supports more than one implementation.
spring.ai.chat.client.enabled=false

# Set max attempts when retrying AI calls.
spring.ai.retry.max-attempts=2

# OpenAI configuration.
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.chat.options.temperature=0
spring.ai.openai.chat.options.model=gpt-4o
spring.ai.openai.embedding.options.model=text-embedding-3-large

# Mistral AI configuration.
spring.ai.mistralai.api-key=${MISTRALAI_API_KEY}
spring.ai.mistralai.chat.options.temperature=0
spring.ai.mistralai.chat.options.model=open-mixtral-8x22b

# Azure Open AI configuration.
spring.ai.azure.openai.apiKey=${AZURE_OPENAI_API_KEY}
spring.ai.azure.openai.chat.options.deployment-name=gpt-4o
spring.ai.azure.openai.chat.options.temperature=0.7

# Ollama configuration.
spring.ai.ollama.chat.model=mistral

# OpenWeatherMap configuration.
openweathermap.api-key=${OPENWEATHERMAP_API_KEY}
